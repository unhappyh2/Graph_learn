{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 源节点特征 (6 个源节点，每个节点 16 维特征)\n",
    "src = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  # 源节点索引\n",
    "    [2, 2, 2, 2, 2, 2],\n",
    "    [3, 3, 3, 3, 3, 3],\n",
    "    [4, 4, 4, 4, 4, 4],  \n",
    "    [5, 5, 5, 5, 5, 5]\n",
    "], dtype=torch.float)\n",
    "tgt = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  \n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1]\n",
    "], dtype=torch.float)\n",
    "adj = torch.tensor([\n",
    "    [0, 3, 4, 1, 4, 1],  # 源节点索引\n",
    "    [0, 0, 0, 1, 1, 2]   # 目标节点索引\n",
    "], dtype=torch.long)\n",
    "print(\"adj[0]:\",adj[0])\n",
    "data = HeteroData()\n",
    "data['src'] = src\n",
    "data['tgt'] = tgt\n",
    "data['adj'] = adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__(aggr='sum', flow='source_to_target')\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.matrix = nn.Parameter(torch.randn(in_channels, in_channels, requires_grad=True))\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        x_src, x_tgt, edge_index = data['src'], data['tgt'], data['adj']\n",
    "        out = self.propagate(x_src=x_src, x_tgt=x_tgt,edge_index=edge_index)\n",
    "        #out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def message(self, x_src,edge_index):\n",
    "        message_src = x_src[edge_index[0]]\n",
    "        return message_src\n",
    "    \n",
    "    def aggregate(self, inputs, edge_index, dim_size=None):\n",
    "        weights = self.calculate_weights(edge_index[1])\n",
    "        weights = weights.view(-1, 1).expand_as(inputs)\n",
    "        inputs = inputs * weights\n",
    "\n",
    "        return super().aggregate(inputs, edge_index[1])\n",
    "    \n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        aggr_out = torch.matmul(aggr_out, self.matrix.t())\n",
    "        aggr_out = self.sigmoid(aggr_out)\n",
    "        return aggr_out\n",
    "    def calculate_weights(self,index):\n",
    "        \"\"\"\n",
    "        计算每个索引位置的权重（根据相同元素的数量）\n",
    "        Args:\n",
    "            index: 索引数组，如 [0,0,0,1,1,2,2,3]\n",
    "        Returns:\n",
    "            weights: 权重数组，如 [0.33,0.33,0.33,0.5,0.5,0.5,0.5,1]\n",
    "        \"\"\"\n",
    "        # 使用 unique_counts 获取每个元素的计数\n",
    "        unique_elements, counts = torch.unique(index, return_counts=True)\n",
    "        \n",
    "        # 创建一个和输入相同大小的权重张量\n",
    "        weights = torch.zeros_like(index, dtype=torch.float)\n",
    "        \n",
    "        # 为每个元素分配权重\n",
    "        for element, count in zip(unique_elements, counts):\n",
    "            weights[index == element] = 1.0 / count.float()\n",
    "        \n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunction(emd_out,data: HeteroData):\n",
    "        x_src = data['src']\n",
    "        edge_index = data['adj']\n",
    "        x_src = x_src[edge_index[0]]\n",
    "        x_src = x_src.t()\n",
    "        simliarity = torch.matmul(emd_out , x_src)\n",
    "        simliarity = torch.sum(simliarity, dim=0)\n",
    "        loss = torch.mean(simliarity)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(6, 6)\n",
    "out = model(data)\n",
    "loss = lossfunction(out,data)\n",
    "print(\"out:\",out)\n",
    "print(\"loss:\",loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10000\n",
    "learning_rate = 0.01\n",
    "loss_list = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(iteration):\n",
    "    out = model(data)\n",
    "    loss = lossfunction(out,data)\n",
    "    loss_list.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"loss:\",loss)\n",
    "print(\"out:\",model(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_weights(self,index):\n",
    "    \"\"\"\n",
    "    计算每个索引位置的权重（根据相同元素的数量）\n",
    "    Args:\n",
    "        index: 索引数组，如 [0,0,0,1,1,2,2,3]\n",
    "    Returns:\n",
    "        weights: 权重数组，如 [0.33,0.33,0.33,0.5,0.5,0.5,0.5,1]\n",
    "    \"\"\"\n",
    "    # 使用 unique_counts 获取每个元素的计数\n",
    "    unique_elements, counts = torch.unique(index, return_counts=True)\n",
    "    \n",
    "    # 创建一个和输入相同大小的权重张量\n",
    "    weights = torch.zeros_like(index, dtype=torch.float)\n",
    "    \n",
    "    # 为每个元素分配权重\n",
    "    for element, count in zip(unique_elements, counts):\n",
    "        weights[index == element] = 1.0 / count.float()\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr: tensor([0.2689, 0.5000, 0.7311, 0.9526, 0.9820])\n",
      "imput: tensor([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 2.,  2.,  2.,  2.,  2.,  2.],\n",
      "        [ 6.,  6.,  6.,  6.,  6.,  6.],\n",
      "        [16., 16., 16., 16., 16., 16.],\n",
      "        [25., 25., 25., 25., 25., 25.]])\n"
     ]
    }
   ],
   "source": [
    "atrr = torch.tensor([0,1,2,4,5])\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "attr = sigmoid(atrr-1)\n",
    "print(\"attr:\",attr)\n",
    "attr = atrr.view(-1,1)\n",
    "imput = src*attr\n",
    "print(\"imput:\",imput)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
