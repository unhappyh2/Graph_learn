{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj[0]: tensor([0, 3, 4, 1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 源节点特征 (6 个源节点，每个节点 16 维特征)\n",
    "src = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  # 源节点索引\n",
    "    [2, 2, 2, 2, 2, 2],\n",
    "    [3, 3, 3, 3, 3, 3],\n",
    "    [4, 4, 4, 4, 4, 4],  \n",
    "    [5, 5, 5, 5, 5, 5]\n",
    "], dtype=torch.float)\n",
    "tgt = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  \n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1]\n",
    "], dtype=torch.float)\n",
    "adj = torch.tensor([\n",
    "    [0, 3, 4, 1, 4, 1],  # 源节点索引\n",
    "    [0, 0, 0, 1, 1, 2]   # 目标节点索引\n",
    "], dtype=torch.long)\n",
    "print(\"adj[0]:\",adj[0])\n",
    "data = HeteroData()\n",
    "data['src'] = src\n",
    "data['tgt'] = tgt\n",
    "data['adj'] = adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__(aggr='sum', flow='source_to_target')\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        x_src, x_tgt, edge_index = data['src'], data['tgt'], data['adj']\n",
    "        out = self.propagate(x_src=x_src, x_tgt=x_tgt,edge_index=edge_index)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def message(self, x_src,edge_index):\n",
    "        message_src = x_src[edge_index[0]]\n",
    "        return message_src\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunction(emd_out,data: HeteroData):\n",
    "        x_src = data['src']\n",
    "        edge_index = data['adj']\n",
    "        x_src = x_src[edge_index[0]]\n",
    "        x_src = x_src.t()\n",
    "        simliarity = torch.matmul(emd_out , x_src)\n",
    "        simliarity = torch.sum(simliarity, dim=0)\n",
    "        loss = torch.mean(simliarity)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(5.9770, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GNN(6, 6)\n",
    "out = model(data)\n",
    "loss = lossfunction(out,data)\n",
    "print(\"loss:\",loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(-22224.1816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-24447.2324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-26670.2832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-28893.3359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-31116.3848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-33339.4414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-35562.4883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-37785.5391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-40008.5859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(-42231.6367, grad_fn=<MeanBackward0>)\n",
      "out: tensor([[-1217.3284, -1216.5657, -1217.8594, -1219.7936, -1223.4185, -1223.5702],\n",
      "        [ -858.2513,  -857.6175,  -858.6173,  -859.9014,  -862.4227,  -862.4664],\n",
      "        [ -259.7892,  -259.3703,  -259.8803,  -260.0811,  -260.7632,  -260.6266]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "iteration = 1000\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(iteration):\n",
    "    out = model(data)\n",
    "    loss = lossfunction(out,data)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"loss:\",loss)\n",
    "print(\"out:\",model(data))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
