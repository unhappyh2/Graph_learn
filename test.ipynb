{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj[0]: tensor([0, 3, 4, 1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 源节点特征 (6 个源节点，每个节点 16 维特征)\n",
    "src = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  # 源节点索引\n",
    "    [2, 2, 2, 2, 2, 2],\n",
    "    [3, 3, 3, 3, 3, 3],\n",
    "    [4, 4, 4, 4, 4, 4],  \n",
    "    [5, 5, 5, 5, 5, 5]\n",
    "], dtype=torch.float)\n",
    "tgt = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 1],  \n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1]\n",
    "], dtype=torch.float)\n",
    "adj = torch.tensor([\n",
    "    [0, 3, 4, 1, 4, 1],  # 源节点索引\n",
    "    [0, 0, 0, 1, 1, 2]   # 目标节点索引\n",
    "], dtype=torch.long)\n",
    "print(\"adj[0]:\",adj[0])\n",
    "data = HeteroData()\n",
    "data['src'] = src\n",
    "data['tgt'] = tgt\n",
    "data['adj'] = adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__(aggr='sum', flow='source_to_target')\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.matrix = nn.Parameter(torch.randn(in_channels, in_channels, requires_grad=True))\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        x_src, x_tgt, edge_index = data['src'], data['tgt'], data['adj']\n",
    "        out = self.propagate(x_src=x_src, x_tgt=x_tgt,edge_index=edge_index)\n",
    "        #out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    def message(self, x_src,edge_index):\n",
    "        message_src = x_src[edge_index[0]]\n",
    "        return message_src\n",
    "    \n",
    "    def aggregate(self, inputs, edge_index, dim_size=None):\n",
    "        weights = self.calculate_weights(edge_index[1])\n",
    "        weights = weights.view(-1, 1).expand_as(inputs)\n",
    "        inputs = inputs * weights\n",
    "\n",
    "        return super().aggregate(inputs, edge_index[1])\n",
    "    \n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        aggr_out = torch.matmul(aggr_out, self.matrix.t())\n",
    "        aggr_out = self.sigmoid(aggr_out)\n",
    "        return aggr_out\n",
    "    def calculate_weights(self,index):\n",
    "        \"\"\"\n",
    "        计算每个索引位置的权重（根据相同元素的数量）\n",
    "        Args:\n",
    "            index: 索引数组，如 [0,0,0,1,1,2,2,3]\n",
    "        Returns:\n",
    "            weights: 权重数组，如 [0.33,0.33,0.33,0.5,0.5,0.5,0.5,1]\n",
    "        \"\"\"\n",
    "        # 使用 unique_counts 获取每个元素的计数\n",
    "        unique_elements, counts = torch.unique(index, return_counts=True)\n",
    "        \n",
    "        # 创建一个和输入相同大小的权重张量\n",
    "        weights = torch.zeros_like(index, dtype=torch.float)\n",
    "        \n",
    "        # 为每个元素分配权重\n",
    "        for element, count in zip(unique_elements, counts):\n",
    "            weights[index == element] = 1.0 / count.float()\n",
    "        \n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunction(emd_out,data: HeteroData):\n",
    "        x_src = data['src']\n",
    "        edge_index = data['adj']\n",
    "        x_src = x_src[edge_index[0]]\n",
    "        x_src = x_src.t()\n",
    "        simliarity = torch.matmul(emd_out , x_src)\n",
    "        simliarity = torch.sum(simliarity, dim=0)\n",
    "        loss = torch.mean(simliarity)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[1.0000, 0.9940, 0.0513, 0.9243, 0.9920, 0.8351],\n",
      "        [1.0000, 0.9954, 0.0447, 0.9326, 0.9937, 0.8460],\n",
      "        [0.9999, 0.9556, 0.1481, 0.8177, 0.9475, 0.7258]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "loss: tensor(44.9786, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GNN(6, 6)\n",
    "out = model(data)\n",
    "loss = lossfunction(out,data)\n",
    "print(\"out:\",out)\n",
    "print(\"loss:\",loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(44.9786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.3857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.9032e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(9.4122e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.9460e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.5033e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(8.0828e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.6834e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(7.3039e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.9432e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.6006e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(6.2751e-05, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(5.9659e-05, grad_fn=<MeanBackward0>)\n",
      "out: tensor([[6.2738e-10, 8.1290e-10, 3.4375e-11, 8.7858e-10, 8.2206e-10, 8.5770e-10],\n",
      "        [2.1747e-10, 2.8546e-10, 1.0305e-11, 3.0972e-10, 2.8883e-10, 3.0200e-10],\n",
      "        [3.0097e-06, 3.5158e-06, 5.2692e-07, 3.6835e-06, 3.5395e-06, 3.6308e-06]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "iteration = 10000\n",
    "learning_rate = 0.01\n",
    "loss_list = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(iteration):\n",
    "    out = model(data)\n",
    "    loss = lossfunction(out,data)\n",
    "    loss_list.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"loss:\",loss)\n",
    "print(\"out:\",model(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
